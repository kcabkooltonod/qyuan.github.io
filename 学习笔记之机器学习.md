# 学习笔记之机器学习

## 前言

​		完成TASK1的代码补全题后，我兴冲冲的打开了Typora开始记录我曲折的机器学习过程。从一个对机器学习一无所知的小白，变成略懂机器学习的萌新。这之间是很折磨人的过程，被高中思维绑架的我在大一的一整年似乎什么都没有学到，再加上本身怕麻烦的性格，让我也错过了很多学习的机会。而下定决心做招新题后，通过自己的探索我收获了独立解决问题的能力，也尝试着去顺从内心的想法，同时也有了今后努力的方向，而不是像一只无头苍蝇一样四处碰壁。这很大程度上多亏了我的舍友张某，他可以说是我的大学启蒙导师了。

## 环境搭建

​		言归正传，环境的搭建是最开始折磨我的问题。我花了一整个晚上从Google从csdn上搜索pytorch的安装教程，本来是很简单的工作，但苦于自己小白的身份，带来了很多不必要的灾难，如在下载Anoconda和Cuba的时候C盘爆了，以至于我扩展C盘的时候，D盘的一部分数据无法恢复，这困扰了我很久。再后来安装一些package的时候，多次因为源的问题无法下载一些包例如sklearn和matplotlib，但最终利用搜索引擎还是解决了问题。之后就开始了我机器学习的道路。

## 监督学习与无监督学习

​		从刚开始对机器处理学习这一任务一无所知到了解机器学习，这是一个观念上的巨大转变。所谓监督学习就是告诉计算机要干嘛，例如给定了标签；而无监督学习只是单纯传入不同数据，而不告诉任务。

## 分类器和预测器

Classification就是给出猫狗和牛马的一堆特征让计算机分出什么是猫什么是狗什么是牛马

Regression就是高中学的线性回归拟合题以及其变体，解决类似房价预测等问题。除了线性回归还可以用标准矩阵的方法解决。

## 神经网络   激励函数

​		神经元：每一层神经网络输入输出的结点

​		隐藏层：输入数据层到输出数据层之间对数据进行运算处理的部位

​		卷积：在数学上是两个函数的翻转加移动，在神经网络中是对像素进行平滑处理并提取特征的过程，也是卷积神经网络的第一步。

​		激励函数：对输入数据进行激活，将其转换为更符合现实的非线性问题，有relu，sigmoid，tanh等。

​		向量化：处理大数据集的时候将多项数据转变成一个向量，对其进行一些运算时可以避免for循环以此提高运行效率。

​		梯度：与函数的偏导数差不多，有方向。

​		优化器：对拟合结果进行误差分析并使下一次拟合更接近局部最优的工具。

​		SGD优化器：最基础的优化器，随机梯度下降，在下降过程中，不同的学习率会对影响效果，学习率太大会导致在最优解处震荡，太小会导致时间长效率低。

​		Adam优化器：效率最高，效果最好的优化器，与SGD相比就相当于一个是没穿鞋的醉酒大汉，一个是穿了足力健的年轻小伙子，两者在下山时后者效率更高，速度更快。

## 训练集与测试集

​		训练集：先提供给计算机用来训练模型的数据集

​		测试集：带入模型计算预测值的数据集



iris数据集执行结果：

![](TASK1\Snipaste_2022-10-03_15-57-03.png)